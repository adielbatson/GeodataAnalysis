{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210936ac-7e20-4cac-89a5-07e92cfc746d",
   "metadata": {},
   "source": [
    "#### Connection Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517049b2-d53e-4642-8aa9-e88260db450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"opendata.dwd.de\"\n",
    "user   = \"anonymous\"\n",
    "passwd = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e154ad-9a10-4481-8988-d4bc32101f1b",
   "metadata": {},
   "source": [
    "#### FTP Directory Definition and Station Description Filename Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b86e5f-e64a-4290-8c21-5397e2e3c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dir = \"/hourly/precipitation/recent/\"\n",
    "station_desc_pattern = \"_Beschreibung_Stationen.txt\"\n",
    "ftp_climate_data_dir = \"/climate_environment/CDC/observations_germany/climate/\"\n",
    "ftp_dir =  ftp_climate_data_dir + topic_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207cf522-79ca-4b9a-b9b1-04744f7647c6",
   "metadata": {},
   "source": [
    "#### Creating local Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5cb52f-1ca4-4fe1-b2dd-de0c0061a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_ftp_dir         = \"../data_pp/original/\"      # Local directory to store local ftp data copies\n",
    "local_ftp_station_dir = local_ftp_dir + topic_dir  # Local directory where local station info is located\n",
    "local_ftp_ts_dir      = local_ftp_dir + topic_dir  # Local directory where time series downloaded from ftp are located\n",
    "\n",
    "local_generated_dir   = \"../data_pp/generated/\"          # The generated of derived data in contrast to local_ftp_dir\n",
    "local_station_dir     = local_generated_dir + topic_dir # Derived station data\n",
    "local_ts_merged_dir   = local_generated_dir + topic_dir # Parallelly merged time series, wide data frame with one TS per column\n",
    "local_ts_appended_dir = local_generated_dir + topic_dir # Serially appended time series, long data frame for QGIS TimeManager Plugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de734bd-1f91-4d25-ae91-a9b807012d98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(local_ftp_station_dir)\n",
    "print(local_ftp_ts_dir)\n",
    "print()\n",
    "print(local_generated_dir)\n",
    "print(local_station_dir)\n",
    "print(local_ts_merged_dir)\n",
    "print(local_ts_appended_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2ad6b-52fe-449a-a37b-a19c3207514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(local_ftp_dir,exist_ok = True)\n",
    "os.makedirs(local_ftp_station_dir,exist_ok = True)\n",
    "os.makedirs(local_ftp_ts_dir,exist_ok = True)\n",
    "\n",
    "os.makedirs(local_generated_dir,exist_ok = True)\n",
    "os.makedirs(local_station_dir,exist_ok = True)\n",
    "os.makedirs(local_ts_merged_dir,exist_ok = True)\n",
    "os.makedirs(local_ts_appended_dir,exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c455a19-a883-4b3d-9462-6b38a7802e42",
   "metadata": {},
   "source": [
    "#### FTP Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7514e-a90f-4b58-ba00-b2db74adde90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "ftp = ftplib.FTP(server)\n",
    "res = ftp.login(user=user, passwd = passwd)\n",
    "print(res)\n",
    "\n",
    "ret = ftp.cwd(\".\")\n",
    "\n",
    "#ftp.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839da593-75ea-4f9c-940c-052c2876ae54",
   "metadata": {},
   "source": [
    "#### Generate Pandas Dataframe from FTP Directory Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d94f31-4773-492c-8e5e-4b544f8afe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def gen_df_from_ftp_dir_listing(ftp, ftpdir):\n",
    "    lines = []\n",
    "    flist = []\n",
    "    try:\n",
    "        # issue the command LIST in the FTP connection \n",
    "        res = ftp.retrlines(\"LIST \"+ftpdir, lines.append)\n",
    "    except:\n",
    "        print(\"Error: ftp.retrlines() failed. ftp timeout? Reconnect!\")\n",
    "        return\n",
    "        \n",
    "    if len(lines) == 0:\n",
    "        print(\"Error: ftp dir is empty\")\n",
    "        return\n",
    "    \n",
    "    for line in lines:\n",
    "#        print(line)\n",
    "        [ftype, fsize, fname] = [line[0:1], int(line[31:42]), line[56:]]\n",
    "        \n",
    "        fext = os.path.splitext(fname)[-1]\n",
    "        \n",
    "        if fext == \".zip\":\n",
    "            station_id = int(fname.split(\"_\")[2])\n",
    "        else:\n",
    "            station_id = -1 \n",
    "        \n",
    "        flist.append([station_id, fname, fext, fsize, ftype])\n",
    "        \n",
    "    df_ftpdir = pd.DataFrame(flist,columns=[\"station_id\", \"name\", \"ext\", \"size\", \"type\"])\n",
    "    return(df_ftpdir)\n",
    "df_ftpdir = gen_df_from_ftp_dir_listing(ftp, ftp_dir)\n",
    "df_ftpdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4d83b-b24a-4549-b993-254345e3aecb",
   "metadata": {},
   "source": [
    "#### Download and Process the Station Description File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9619e-f9c8-4f3e-8386-6549715021e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ftplib\n",
    "\n",
    "encoding = \"latin1\" # German Umlaute\n",
    "\n",
    "def grabFile(ftp,ftpfullname,localfullname):\n",
    "    try:\n",
    "        ret = ftp.cwd(\".\") \n",
    "        localfile = open(localfullname, 'wb')\n",
    "        ftp.retrbinary('RETR ' + ftpfullname, localfile.write, 1024)\n",
    "        localfile.close()\n",
    "    \n",
    "    except ftplib.error_perm:\n",
    "        print(\"FTP ERROR. Operation not permitted. File not found?\")\n",
    "\n",
    "    except ftplib.error_temp:\n",
    "        print(\"FTP ERROR. Timeout.\")\n",
    "\n",
    "    except ConnectionAbortedError:\n",
    "        print(\"FTP ERROR. Connection aborted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0f129-736d-462f-84eb-ea528637e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_fname = df_ftpdir[df_ftpdir['name'].str.contains(station_desc_pattern)][\"name\"].values[0]\n",
    "print(\"Station description file name:\\n%s\" % (station_fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b637316-abb9-426e-aaca-a1d58d5888e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = ftp_dir + station_fname\n",
    "dest = local_ftp_station_dir + station_fname\n",
    "print(\"grabFile(ftp, src, dest):\")\n",
    "print(\"FTP source: \" + src)\n",
    "print(\"Local dest:   \" + dest)\n",
    "grabFile(ftp, src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001fd74-b6b7-49d4-9b82-0397c558b060",
   "metadata": {},
   "source": [
    "#### Rename the Column Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4248c9a-b316-47d6-80eb-9b65f748e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def station_desc_txt_to_csv(txtfile, csvfile):\n",
    "    import pandas as pd\n",
    "    \n",
    "    file = codecs.open(txtfile,\"r\",encoding)\n",
    "    r = file.readline()\n",
    "    file.close()\n",
    "    colnames_de = r.split()\n",
    "    colnames_de\n",
    "    \n",
    "    # German-English dictionary\n",
    "    translate = \\\n",
    "    {'Stations_id':'station_id',\n",
    "     'von_datum':'date_from',\n",
    "     'bis_datum':'date_to',\n",
    "     'Stationshoehe':'altitude',\n",
    "     'geoBreite': 'latitude',\n",
    "     'geoLaenge': 'longitude',\n",
    "     'Stationsname':'name',\n",
    "     'Bundesland':'state'}\n",
    "    \n",
    "    colnames_en = [translate[h] for h in colnames_de]\n",
    "    \n",
    "    # Skip the first two rows and set the column names.\n",
    "    df = pd.read_fwf(txtfile,skiprows=2,names=colnames_en, parse_dates=[\"date_from\",\"date_to\"],index_col = 0,encoding=encoding)\n",
    "    \n",
    "    # write CSV file with field separator semicolon\n",
    "    df.to_csv(csvfile, sep = \";\")\n",
    "    return(df)\n",
    "\n",
    "basename = os.path.splitext(station_fname)[0]\n",
    "df_stations = station_desc_txt_to_csv(local_ftp_station_dir + station_fname, local_station_dir + basename + \".csv\")\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b12b9-b716-4585-8f1b-e51944c12938",
   "metadata": {},
   "source": [
    "### Select only Stations Located in NRW and being Operational "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10135050-59af-4300-bcb6-9f9d7131c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "isNRW = df_stations['state'].str.contains(\"Nordrhein\")\n",
    "\n",
    "isOperational = df_stations['date_to'] == df_stations.date_to.max() \n",
    "\n",
    "isBefore2021 = df_stations['date_from'] < '2021'\n",
    "\n",
    "dfNRW = df_stations[isNRW & isOperational & isBefore2021]\n",
    "\n",
    "print(\"Number of stations in NRW: \\n\", dfNRW.count())\n",
    "dfNRW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e692db2-fb8f-434c-8d2d-bec105dda8b1",
   "metadata": {},
   "source": [
    "### Creating a Geo Data Frame - Geopandas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e737a1-4abd-46c6-998f-6cccb077260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "conda_prefix = os.environ['conda_prefix']\n",
    "print(f\"CONDA_PREFIX: {conda_prefix:s}\")\n",
    "os.environ['proj_lib'] = conda_prefix + r\"\\Library\\share\\proj\"\n",
    "proj_lib = os.environ['proj_lib']\n",
    "print(f\"New env var value: \\nPROJ_LIB={proj_lib:s}\")\n",
    "\n",
    "import pyproj\n",
    "print(f\"pyproj.datadir.get_data_dir() -> {pyproj.datadir.get_data_dir():s}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac1688-d800-4dae-8abb-9eea1009299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import fiona\n",
    "from pyproj import CRS\n",
    "\n",
    "#df = pd.read_csv('data.csv')\n",
    "df = dfNRW\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df.longitude, df.latitude)]\n",
    "crs = CRS(\"epsg:4326\") #http://www.spatialreference.org/ref/epsg/2263/\n",
    "stations_gdf = GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "\n",
    "stations_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52480b85-d226-4695-950a-4494f34fd5e6",
   "metadata": {},
   "source": [
    "#### Connecting to the PostGIS database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bcf708-a0a9-4987-882d-b89e26188700",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dic = {\n",
    "  \"user\" : \"geo_master\",\n",
    "  \"pw\"   : \"xxxxxx\",\n",
    "  \"host\" : \"localhost\",\n",
    "  \"db\"   : \"geo\"\n",
    "}\n",
    "\n",
    "template = \"postgresql://{user}:{pw}@{host}:5432/{db}\"\n",
    "\n",
    "db_connection_url = template.format(**param_dic)\n",
    "print(\"Connection URL: \", db_connection_url) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88fded-ca4e-45fa-9bea-f55de2caab20",
   "metadata": {},
   "source": [
    "### Write Geopandas Data Frame directly into PostGIS Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c29289-3f01-413c-b569-efa754b429bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Numeric, Float, Date, REAL\n",
    "#import psycopg2\n",
    "\n",
    "engine = create_engine(db_connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22b7a5-a664-44aa-a693-8366027466ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\"station_id\": Numeric(6,0), \"altitude\" : REAL, \"date_from\" : Date, \"date_to\" : Date, \"longitude\" : REAL, \"latitude\" : REAL}\n",
    "\n",
    "engine.execute(\"DROP VIEW IF EXISTS dwd.v_stations_prec\")\n",
    "\n",
    "stations_gdf.to_postgis(name=\"stations\", schema=\"dwd\", if_exists = \"replace\", index = \"station_id\", index_label=True, con=engine, dtype=dtypes)\n",
    "\n",
    "engine.execute('alter table dwd.stations add primary key (station_id)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c91d6-4044-4308-b3c1-7de86ac1834c",
   "metadata": {},
   "source": [
    "## Download and Process the Time Series Zip Archives\n",
    "### Dataframe with TS Zip Files from FTP Directory Listing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6f2da-3ed0-4a07-a82c-5074f51f07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zips = df_ftpdir[df_ftpdir[\"ext\"]==\".zip\"]\n",
    "df_zips.set_index(\"station_id\", inplace = True)\n",
    "df_zips.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af264e6-8379-44a7-8bab-8c5c2d58f21b",
   "metadata": {},
   "source": [
    "### Download TS Data from FTP Server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6608dd9-2a3e-40f7-9e13-dbc722f84721",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip_list = []\n",
    "\n",
    "station_ids_selected = list(dfNRW.index)\n",
    "\n",
    "for station_id in station_ids_selected:\n",
    "    try:\n",
    "        fname = df_zips[\"name\"][station_id]\n",
    "        print(fname)\n",
    "        grabFile(ftp, ftp_dir + fname, local_ftp_ts_dir + fname)\n",
    "        local_zip_list.append(fname)\n",
    "    except:\n",
    "        print(\"WARNING: TS file for key %d not found in FTP directory.\" % station_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724d09a-9a9d-4cde-9cc5-53270001b426",
   "metadata": {},
   "source": [
    "### Write the time series to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffabfdb-f13b-41d3-af32-3a1d054ff67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "def prec_ts_to_df(fname):\n",
    "\n",
    "    import pandas as pd\n",
    "    import pytz\n",
    "    from datetime import datetime\n",
    "    \n",
    "    dateparse = lambda dates: [datetime.strptime(str(d), '%Y%m%d%H') for d in dates]\n",
    "\n",
    "    df = pd.read_csv(fname, delimiter=\";\", encoding=encoding, index_col=\"MESS_DATUM\", parse_dates = [\"MESS_DATUM\"], date_parser = dateparse, na_values = [-999.0, -999])\n",
    "\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_', regex=False).str.replace('(', '', regex=False).str.replace(')', '', regex=False)\n",
    "    df.index.name = df.index.name.strip().lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    \n",
    "    # TIME ZONES: https://stackoverflow.com/questions/22800079/converting-time-zone-pandas-dataframe\n",
    "    # DWD Prec Data is given in UTC\n",
    "    \n",
    "    df.index = df.index.tz_localize(pytz.utc)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4aef5f-89a8-4554-a3f5-f5b6afd36042",
   "metadata": {},
   "source": [
    "#### The database writer (SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e637b-95e4-4867-aba5-0cba86ea6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "\n",
    "dtypes = {\"station_id\": Numeric(6,0), \"val\" : REAL}\n",
    "\n",
    "#for elt in local_zip_list[0:1]:\n",
    "for elt in local_zip_list:\n",
    "    ffname = local_ftp_ts_dir + elt\n",
    "    #print(\"Zip archive: \" + ffname)\n",
    "    with ZipFile(ffname) as myzip:\n",
    "        # read the time series data from the file starting with \"produkt\"\n",
    "        prodfilename = [elt for elt in myzip.namelist() if elt.split(\"_\")[0]==\"produkt\"][0] \n",
    "        print(\"Extract product file: %s\" % prodfilename)\n",
    "        # print()\n",
    "        with myzip.open(prodfilename) as myfile:\n",
    "            dftmp = prec_ts_to_df(myfile)[[\"stations_id\",\"r1\"]]\n",
    "            # df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)\n",
    "            dftmp.rename(columns={'stations_id': 'station_id', 'r1': 'val', 'mess_datum': 'ts'}, inplace = True)\n",
    "            dftmp.rename_axis('ts', inplace = True)\n",
    "            # dftmp.to_csv(f, header=f.tell()==0)\n",
    "            if (first):\n",
    "                first = False\n",
    "                # dftmp.to_csv(csvfname, mode = \"w\", header = False)\n",
    "                dftmp.to_sql(name=\"prec\", schema=\"dwd\", if_exists = \"replace\", index = [\"ts\"], index_label=True, con=engine, dtype=dtypes)\n",
    "            else:\n",
    "                # dftmp.to_csv(csvfname, mode = \"a\", header = False)\n",
    "                dftmp.to_sql(name=\"prec\", schema=\"dwd\", if_exists = \"append\",  index = [\"ts\"], index_label=True, con=engine, dtype=dtypes)\n",
    "\n",
    "# After insert completed: ceate index\n",
    "print(\"create index\")\n",
    "engine.execute(\"ALTER TABLE dwd.prec ADD PRIMARY KEY (ts, station_id)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b5f69-718c-4dfd-80b0-bde6b6b0a19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
